{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir= \"../data/raw_data/Training\"\n",
    "test_data_dir = \"../data/raw_data/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(train_data_dir)\n",
    "\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(train_data_dir, fold)\n",
    "    filelist = os.listdir(foldpath)\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "train_df = pd.concat([Fseries, Lseries], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train_df,  train_size=0.8 , shuffle= True, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>../data/raw_data/Training/glioma/Tr-gl_0394.jp...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>../data/raw_data/Training/glioma/Tr-gl_0702.jp...</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>../data/raw_data/Training/meningioma/Tr-me_042...</td>\n",
       "      <td>meningioma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>../data/raw_data/Training/pituitary/Tr-pi_1338...</td>\n",
       "      <td>pituitary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>../data/raw_data/Training/glioma/Tr-gl_0339.jpg</td>\n",
       "      <td>glioma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filepaths      labels\n",
       "2487  ../data/raw_data/Training/glioma/Tr-gl_0394.jp...      glioma\n",
       "2542  ../data/raw_data/Training/glioma/Tr-gl_0702.jp...      glioma\n",
       "3528  ../data/raw_data/Training/meningioma/Tr-me_042...  meningioma\n",
       "5720  ../data/raw_data/Training/pituitary/Tr-pi_1338...   pituitary\n",
       "829     ../data/raw_data/Training/glioma/Tr-gl_0339.jpg      glioma"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 files belonging to 4 classes.\n",
      "Using 4570 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:13:21.626618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-12-11 11:13:21.626706: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-12-11 11:13:21.626738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-EP40TTE): /proc/driver/nvidia/version does not exist\n",
      "2024-12-11 11:13:21.628864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 files belonging to 4 classes.\n",
      "Using 1142 files for validation.\n",
      "Found 1311 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the image size and batch size\n",
    "IMAGE_SIZE =(256,256)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Training and validation datasets\n",
    "X_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,  # Use 20% of the data for validation\n",
    "    subset=\"training\",  # Specify the subset\n",
    "    seed=42,  # Ensure reproducibility\n",
    "    image_size=IMAGE_SIZE,  # Resize images to 128x128\n",
    "    batch_size=BATCH_SIZE  # Batch size\n",
    ")\n",
    "\n",
    "\n",
    "X_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "X_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    shuffle =False,\n",
    "    seed=42,  # Ensure reproducibility\n",
    "    image_size=IMAGE_SIZE,  # Resize images to 128x128\n",
    "    batch_size=16  # Batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Apply normalization to transform images into float32\n",
    "X_train_normalized = X_train.map(normalize_img)\n",
    "X_val_normalized = X_val.map(normalize_img)\n",
    "\n",
    "#Apply MRI-specific normalization:\n",
    "def mri_normalize(image, label):\n",
    "    \"\"\"Applies MRI-specific normalization.\"\"\"\n",
    "    # Z-score normalization\n",
    "    mean = tf.reduce_mean(image)\n",
    "    std = tf.math.reduce_std(image)\n",
    "    normalized_image = (image - mean) / std\n",
    "    return normalized_image, label\n",
    "\n",
    "X_train_normalized = X_train_normalized.map(mri_normalize)\n",
    "X_val_normalized = X_val_normalized.map(mri_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(4, activation='softmax')(x)  # Adjust the number of classes as needed\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_normalized,\n",
    "    validation_data=X_test,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot learning curves\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
